{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction\n",
    "## 1.1 What is GMNS?\n",
    "The General Modeling Network Specification (GMNS)defines a set of flexible and unified multi-mode traffic network representation format, which is mainly convenient for researchers to share and merge network data from different channels.It covers a variety of network types, adopts a unified format, and is suitable for various traffic network modeling purposes.If you want to learn more about GMNS, you may as well click the link https://github.com/asu-trans-ai-lab/Path4GMNS/blob/master/path4gmns.ipynb. For more information about GMNS format,please refer to https://github.com/asu-trans-ai-lab/osm_test_data_set.\n",
    "## 1.2 What is Pandas?\n",
    "It was originally developed by AQR capital management in April 2008 and was open source at the end of 2009.At present,it is continuously developed and maintained by pydata development team, which focuses on Python data package development.It is a part of pydata project.\n",
    "In order to use pandas more effectively, we recommend using anacaonda as your ide.If you have done so, you can view information about pandas by executing the following command at the anaconda power shell prompt.For example:\n",
    "- Check the panda version: enter the \"CONDA list\" command to check whether the panda is installed. If pandas is installed on your computer, you can get a list of its version information in the console.\n",
    "- Install Panda: if you haven't installed panda, please enter the \"PIP install Panda\" command. Anaconda will automatically download and install the latest version of panda.\n",
    "- Unload Panda: if you want to unload panda, you should use \"PIP unload Panda\" command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 How to use panda to process GMNS data?\n",
    "In this section, some examples illustrate the basic process of GMNS data processing with pandas.It should be noted that once you locate your online dataset from Github, you may need to make some minor adjustments.For ease of exposition,let's use the node.csv,link.csv and zone.csv to show the basic process for using panda to process GMNS data.we can learn based on the data set https://github.com/asu-trans-ai-lab/QGIS_NeXTA4GMNS/tree/master/datasets.\n",
    "## 2.1 Example of using node.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version is 1.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  #import pandas package\n",
    "print('Pandas version is ' + pd.__version__) #search the pandas version in python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of nodes is 219\n"
     ]
    }
   ],
   "source": [
    "df_node=pd.read_csv(r'F:\\python\\ASU\\macronet\\node.csv') # read node.csv file\n",
    "nodeCnt = df_node.index #get the count of the node.csv\n",
    "print('the number of nodes is {0}'.format(len(nodeCnt))) # output the number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Example of using link.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'link_id', 'from_node_id', 'to_node_id', 'facility_type',\n",
      "       'dir_flag', 'length', 'lanes', 'capacity', 'free_speed', 'link_type',\n",
      "       'cost', 'geometry', 'TMC'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #import pandas Package\n",
    "df_link =pd.read_csv(r'F:\\python\\ASU\\macronet\\link.csv') # read link.csv file\n",
    "print(df_link.columns) #get the field set in link.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   name  link_id  from_node_id  to_node_id  facility_type  dir_flag  \\\n",
      "0   NaN        0             9         226            NaN       NaN   \n",
      "1   NaN        1           226           9            NaN       NaN   \n",
      "2   NaN        2           158         254            NaN       NaN   \n",
      "\n",
      "       length  lanes  capacity  free_speed  link_type  cost  \\\n",
      "0  139.285820      1       NaN    -1.60934          1   NaN   \n",
      "1  146.101478      1       NaN    -1.60934          1   NaN   \n",
      "2  110.436568      1       NaN    40.23350          1   NaN   \n",
      "\n",
      "                                            geometry  TMC  \n",
      "0  LINESTRING (-111.93039 33.42312,-111.93038 33....  NaN  \n",
      "1  LINESTRING (-111.9297 33.42413,-111.93013 33.4...  NaN  \n",
      "2  LINESTRING (-111.94127 33.42431,-111.94071 33....  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df_link.head(3)) #get the first three record in link.csv, and you can change the parameter based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  link_id  from_node_id  to_node_id  facility_type  dir_flag  \\\n",
      "155   NaN      164           111         107            NaN       NaN   \n",
      "\n",
      "         length  lanes  capacity  free_speed  link_type  cost  \\\n",
      "155  508.119779      1       NaN    -1.60934          1   NaN   \n",
      "\n",
      "                                              geometry  TMC  \n",
      "155  LINESTRING (-111.92628 33.42009,-111.92614 33....  NaN  \n"
     ]
    }
   ],
   "source": [
    "# sort one column in link.csv and get the row that contains the maximum value of the column\n",
    "lenSort = df_link.sort_values('length', ascending=False, kind='quicksort', ignore_index=False)\n",
    "print(lenSort.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508.11977870229583\n"
     ]
    }
   ],
   "source": [
    "print(df_link['length'].max()) # get the length of the longest link in link.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                                           NaN\n",
      "link_id                                                          1\n",
      "from_node_id                                                   226\n",
      "to_node_id                                                       9\n",
      "facility_type                                                  NaN\n",
      "dir_flag                                                       NaN\n",
      "length                                                  146.101478\n",
      "lanes                                                            1\n",
      "capacity                                                       NaN\n",
      "free_speed                                                -1.60934\n",
      "link_type                                                        1\n",
      "cost                                                           NaN\n",
      "geometry         LINESTRING (-111.9297 33.42413,-111.93013 33.4...\n",
      "TMC                                                            NaN\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_link.loc[1]) # get the content in the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  link_id  from_node_id  to_node_id  facility_type  dir_flag  \\\n",
      "0     NaN        0             9         226            NaN       NaN   \n",
      "1     NaN        1           226           9            NaN       NaN   \n",
      "2     NaN        2           158         254            NaN       NaN   \n",
      "3     NaN        3           254         158            NaN       NaN   \n",
      "4     NaN        4            13          86            NaN       NaN   \n",
      "..    ...      ...           ...         ...            ...       ...   \n",
      "503   NaN      540            67          66            NaN       NaN   \n",
      "504   NaN      541           227         226            NaN       NaN   \n",
      "505   NaN      542           226         227            NaN       NaN   \n",
      "506   NaN      543           234          28            NaN       NaN   \n",
      "507   NaN      544           236         238            NaN       NaN   \n",
      "\n",
      "         length  lanes  capacity  free_speed  link_type  cost  \\\n",
      "0    139.285820      1       NaN    -1.60934          1   NaN   \n",
      "1    146.101478      1       NaN    -1.60934          1   NaN   \n",
      "2    110.436568      1       NaN    40.23350          1   NaN   \n",
      "3    110.435301      1       NaN    40.23350          1   NaN   \n",
      "4    156.978514      1       NaN    40.23350          1   NaN   \n",
      "..          ...    ...       ...         ...        ...   ...   \n",
      "503  164.425098      1       NaN    -1.60934          1   NaN   \n",
      "504  194.710904      1       NaN    -1.60934          1   NaN   \n",
      "505  198.666321      1       NaN    -1.60934          1   NaN   \n",
      "506    6.390731      1       NaN    -1.60934          1   NaN   \n",
      "507    6.551988      1       NaN    -1.60934          1   NaN   \n",
      "\n",
      "                                              geometry  TMC  \n",
      "0    LINESTRING (-111.93039 33.42312,-111.93038 33....  NaN  \n",
      "1    LINESTRING (-111.9297 33.42413,-111.93013 33.4...  NaN  \n",
      "2    LINESTRING (-111.94127 33.42431,-111.94071 33....  NaN  \n",
      "3    LINESTRING (-111.94008 33.42438,-111.94071 33....  NaN  \n",
      "4    LINESTRING (-111.93667 33.42433,-111.93656 33....  NaN  \n",
      "..                                                 ...  ...  \n",
      "503  LINESTRING (-111.93492 33.42547,-111.93506 33....  NaN  \n",
      "504  LINESTRING (-111.92786 33.42334,-111.92817 33....  NaN  \n",
      "505  LINESTRING (-111.92972 33.42408,-111.92966 33....  NaN  \n",
      "506  LINESTRING (-111.94233 33.42047,-111.94233 33....  NaN  \n",
      "507  LINESTRING (-111.94119 33.42048,-111.94119 33....  NaN  \n",
      "\n",
      "[389 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_link[df_link['lanes']==1]) #get the links with 1 lane in link.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Example of using zone.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of zones is 150\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #import pandas package\n",
    "df_zone=pd.read_csv(r'F:\\python\\ASU\\macronet\\zone.csv') #read zone.csv file\n",
    "print('the total number of zones is {0}'.format(len(df_zone.index))) #get the total number of zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   zone_id      name                                           geometry\n",
      "0        1  A2 - 161  POLYGON ((-111.945007 33.427002, -111.944008 3...\n",
      "1        2    A3 - 1  POLYGON ((-111.945007 33.426003, -111.944008 3...\n",
      "2        6    A7 - 2  POLYGON ((-111.945007 33.422001, -111.944008 3...\n",
      "3        7    A8 - 3  POLYGON ((-111.945007 33.421001, -111.944008 3...\n",
      "4        9   A10 - 4  POLYGON ((-111.945007 33.419003, -111.944008 3...\n",
      "5       13   A14 - 5  POLYGON ((-111.945007 33.415001, -111.944008 3...\n",
      "6       16   A17 - 7  POLYGON ((-111.945007 33.412003, -111.944008 3...\n",
      "7       18   A19 - 8  POLYGON ((-111.945007 33.410000, -111.944008 3...\n"
     ]
    }
   ],
   "source": [
    "typeA = df_zone.loc[df_zone['name'].str.contains('A')] #select the zones that start with the letter A\n",
    "print(typeA) # print the row about zones that start with the letter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of fields in zone.csv is 3\n"
     ]
    }
   ],
   "source": [
    "print('the count of fields in zone.csv is {0}'.format(len(typeA.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of the A zone is 8\n"
     ]
    }
   ],
   "source": [
    "print('the count of the A zone is {0}'.format(len(typeA.index))) #get the count of the A zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeA.to_csv(r'F:\\python\\ASU\\macronet\\typeA.csv') #export the rows about A zone to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Example of using online dataset\n",
    "You can also fetch online dataset easily.Now, we will give some useful examples. \n",
    "Firstly, when you get the online resources,some steps will be executed to deal with your Github URL.\n",
    "\n",
    "CaseⅠ:\n",
    "You should insert 'raw.'into your URL. For example,you should modify https://githubusercontent.com/cs109/2014_data/master/countries.csv\n",
    "to https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv\n",
    "\n",
    "CaseⅡ:\n",
    "You should remove 'blob' and replace 'Github' with 'raw.githubsercontent'. For example,you should modify https://github.com/asu-trans-ai-lab/QGIS_NeXTA4GMNS/blob/master/datasets/ASU/macronet/zone.csv\n",
    "to https://raw.githubusercontent.com/asu-trans-ai-lab/QGIS_NeXTA4GMNS/master/datasets/ASU/macronet/zone.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>name</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>node_type</th>\n",
       "      <th>ctrl_type</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017882</td>\n",
       "      <td>-0.125179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (0.017882 -0.125179)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.253933</td>\n",
       "      <td>0.053648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (40.253933 0.053648)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.778254</td>\n",
       "      <td>14.806867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (19.778254 14.806867)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.688841</td>\n",
       "      <td>-9.692418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (19.688841 -9.692418)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id  name    x_coord    y_coord  node_type  ctrl_type  zone_id  \\\n",
       "0        1   NaN   0.017882  -0.125179        NaN        NaN        1   \n",
       "1        2   NaN  40.253933   0.053648        NaN        NaN        2   \n",
       "2        3   NaN  19.778254  14.806867        NaN        NaN        0   \n",
       "3        4   NaN  19.688841  -9.692418        NaN        NaN        0   \n",
       "\n",
       "                      geometry  \n",
       "0   POINT (0.017882 -0.125179)  \n",
       "1   POINT (40.253933 0.053648)  \n",
       "2  POINT (19.778254 14.806867)  \n",
       "3  POINT (19.688841 -9.692418)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url='https://raw.github.com/asu-trans-ai-lab/DTALite/main/dataset/01_two_corridor/node.csv'\n",
    "# https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv\n",
    "# https://raw.githubusercontent.com/asu-trans-ai-lab/QGIS_NeXTA4GMNS/master/datasets/ASU/macronet/zone.csv\n",
    "# https://raw.github.com/asu-trans-ai-lab/DTALite/main/dataset/01_two_corridor/node.csv\n",
    "s=requests.get(url).content\n",
    "pd_url=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "pd_url.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Example of using PivotTable\n",
    "A PivotTable is a powerful tool to calculate, summarize, and analyze data that lets you see comparisons, patterns, and trends in your data.\n",
    "Notes： If you have not used Pivot Table before even an Excel, please refer to the references based Pivot Table link to https://support.microsoft.com/en-us/office/create-a-pivottable-to-analyze-worksheet-data-a9a84538-bfe9-40a9-a8e9-f99134456576 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix Timestamp (local time)</th>\n",
       "      <th>StationID</th>\n",
       "      <th>Total Flow_per_obs_interval</th>\n",
       "      <th>Avg Density</th>\n",
       "      <th>Avg Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/17/2010 00:00</td>\n",
       "      <td>400009</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>68.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/17/2010 00:00</td>\n",
       "      <td>400126</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>70.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/17/2010 00:00</td>\n",
       "      <td>400176</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/17/2010 00:00</td>\n",
       "      <td>400367</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/17/2010 00:00</td>\n",
       "      <td>400432</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>68.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unix Timestamp (local time)  StationID  Total Flow_per_obs_interval  \\\n",
       "0            03/17/2010 00:00     400009                           35   \n",
       "1            03/17/2010 00:00     400126                           24   \n",
       "2            03/17/2010 00:00     400176                           52   \n",
       "3            03/17/2010 00:00     400367                           48   \n",
       "4            03/17/2010 00:00     400432                           53   \n",
       "\n",
       "   Avg Density  Avg Speed  \n",
       "0       0.0103       68.9  \n",
       "1       0.0082       70.6  \n",
       "2       0.0139       71.3  \n",
       "3       0.0148       70.4  \n",
       "4       0.0150       68.3  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import requests\n",
    "url='https://raw.githubusercontent.com/asu-trans-ai-lab/DTALite/main/dataset/11_Berkeley_Highway_Lab-Network/SensorDataDay013.csv'\n",
    "s=requests.get(url).content\n",
    "pd_SensorData=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "pd_SensorData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>StationID</th>\n",
       "      <th>400009</th>\n",
       "      <th>400126</th>\n",
       "      <th>400176</th>\n",
       "      <th>400367</th>\n",
       "      <th>400432</th>\n",
       "      <th>400679</th>\n",
       "      <th>400691</th>\n",
       "      <th>400728</th>\n",
       "      <th>400803</th>\n",
       "      <th>400808</th>\n",
       "      <th>401198</th>\n",
       "      <th>401242</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unix Timestamp (local time)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:00</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:05</th>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:10</th>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:15</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:20</th>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:35</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:40</th>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:45</th>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:50</th>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:55</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "StationID                    400009  400126  400176  400367  400432  400679  \\\n",
       "Unix Timestamp (local time)                                                   \n",
       "03/17/2010 00:00             0.0103  0.0082  0.0139  0.0148  0.0150  0.0173   \n",
       "03/17/2010 00:05             0.0143  0.0111  0.0136  0.0176  0.0165  0.0171   \n",
       "03/17/2010 00:10             0.0135  0.0116  0.0139  0.0148  0.0159  0.0166   \n",
       "03/17/2010 00:15             0.0128  0.0109  0.0143  0.0145  0.0150  0.0153   \n",
       "03/17/2010 00:20             0.0117  0.0089  0.0143  0.0160  0.0134  0.0181   \n",
       "...                             ...     ...     ...     ...     ...     ...   \n",
       "03/17/2010 23:35             0.0184  0.0184  0.0200  0.0213  0.0191  0.0244   \n",
       "03/17/2010 23:40             0.0146  0.0127  0.0183  0.0229  0.0186  0.0246   \n",
       "03/17/2010 23:45             0.0147  0.0152  0.0219  0.0235  0.0174  0.0260   \n",
       "03/17/2010 23:50             0.0124  0.0096  0.0149  0.0150  0.0170  0.0174   \n",
       "03/17/2010 23:55             0.0128  0.0119  0.0133  0.0174  0.0154  0.0215   \n",
       "\n",
       "StationID                    400691  400728  400803  400808  401198  401242  \n",
       "Unix Timestamp (local time)                                                  \n",
       "03/17/2010 00:00             0.0067  0.0054  0.0066  0.0140  0.0167  0.0061  \n",
       "03/17/2010 00:05             0.0085  0.0097  0.0092  0.0189  0.0170  0.0104  \n",
       "03/17/2010 00:10             0.0104  0.0087  0.0104  0.0147  0.0167  0.0110  \n",
       "03/17/2010 00:15             0.0099  0.0080  0.0108  0.0163  0.0155  0.0094  \n",
       "03/17/2010 00:20             0.0073  0.0051  0.0087  0.0167  0.0175  0.0079  \n",
       "...                             ...     ...     ...     ...     ...     ...  \n",
       "03/17/2010 23:35             0.0161  0.0116  0.0148  0.0219  0.0253  0.0164  \n",
       "03/17/2010 23:40             0.0104  0.0080  0.0116  0.0251  0.0227  0.0110  \n",
       "03/17/2010 23:45             0.0117  0.0097  0.0128  0.0244  0.0260  0.0125  \n",
       "03/17/2010 23:50             0.0087  0.0094  0.0032  0.0060  0.0178  0.0095  \n",
       "03/17/2010 23:55             0.0102  0.0071  0.0026  0.0049  0.0180  0.0089  \n",
       "\n",
       "[288 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_SensorData.pivot(index='Unix Timestamp (local time)', columns='StationID',values='Avg Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Avg Density</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unix Timestamp (local time)</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:00</th>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:05</th>\n",
       "      <td>0.1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:10</th>\n",
       "      <td>0.1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:15</th>\n",
       "      <td>0.1527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 00:20</th>\n",
       "      <td>0.1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:35</th>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:40</th>\n",
       "      <td>0.2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:45</th>\n",
       "      <td>0.2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:50</th>\n",
       "      <td>0.1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/17/2010 23:55</th>\n",
       "      <td>0.1440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sum\n",
       "                            Avg Density\n",
       "Unix Timestamp (local time)            \n",
       "03/17/2010 00:00                 0.1350\n",
       "03/17/2010 00:05                 0.1639\n",
       "03/17/2010 00:10                 0.1582\n",
       "03/17/2010 00:15                 0.1527\n",
       "03/17/2010 00:20                 0.1456\n",
       "...                                 ...\n",
       "03/17/2010 23:35                 0.2277\n",
       "03/17/2010 23:40                 0.2005\n",
       "03/17/2010 23:45                 0.2158\n",
       "03/17/2010 23:50                 0.1409\n",
       "03/17/2010 23:55                 0.1440\n",
       "\n",
       "[288 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(pd_SensorData,index='Unix Timestamp (local time)',values='Avg Density',aggfunc=[np.sum],fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 References\n",
    "- The information for GMNS data format： https://github.com/zephyr-data-specs/GMNS\n",
    "- The official manual for Pandas：https://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html\n",
    "- The test dataset for the artical: https://github.com/asu-trans-ai-lab/QGIS_NeXTA4GMNS/tree/master/datasets\n",
    "- the another dataset: https://github.com/asu-trans-ai-lab/DTALite/tree/main/dataset\n",
    "- How to read CSV file from GitHub using pandas: https://stackoverflow.com/questions/55240330/how-to-read-csv-file-from-github-using-pandas\n",
    "- An Excel based pivot table link: https://support.microsoft.com/en-us/office/create-a-pivottable-to-analyze-worksheet-data-a9a84538-bfe9-40a9-a8e9-f99134456576"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
